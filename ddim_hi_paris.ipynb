{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9d626e8e67ee8e",
   "metadata": {
    "collapsed": false,
    "id": "5a9d626e8e67ee8e",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Introduction to score based generative modelling.\n",
    "\n",
    "In this notebook, we provide an introduction to generative modelling via the **score** of a distribution. If $q_d$ is the density of the distribution of interest, the score of $q_d$ is $ \\nabla \\log q_d(x)\\,. $\n",
    "\n",
    "**Score based generative modelling** consists of estimating the score of a distribution of interest from a set of samples $\\mathcal{D} = \\{X_1, \\cdots, X_n\\}$. Therefore, we search, for a given parametric family $s_{\\theta}(x)$ (i.e. a given network structure), the parameter\n",
    "\n",
    "$$\\theta \\in \\operatorname{argmin}_{\\theta} \\mathbb{E}_{X \\sim q_d}[\\|s_{\\theta}(X) - \\nabla \\log q_d(X)\\|^2] \\,. $$\n",
    "\n",
    "Of course, it is not possible to directly solve the optimization problem presented above, since we do not know the score of the distribution.\n",
    "In this notebook, we will consider three approaches to learning the score of a distribution $p$ without knowing the density (or the score):\n",
    "\n",
    "* [1] Hyvärinen, A. (2005). Estimation of Non-Normalized Statistical Models by Score Matching. Journal of Machine Learning Research, 6(24), 695–709. Retrieved from http://jmlr.org/papers/v6/hyvarinen05a.html\n",
    "\n",
    "* [2] P. Vincent, \"A Connection Between Score Matching and Denoising Autoencoders,\" in Neural Computation, vol. 23, no. 7, pp. 1661-1674, July 2011, doi: 10.1162/NECO_a_00142.\n",
    "\n",
    "* [3] Song, Y., & Ermon, S. (2019). Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems, 32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T00:00:54.915717732Z",
     "start_time": "2024-02-25T00:00:49.440498345Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "outputId": "9b4f451c-792d-4aa4-ddff-7bab4fce8d89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7f2ccddc7dd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "from jax import numpy as jnp, grad, random, vmap, value_and_grad, jit, jvp, jacfwd, devices\n",
    "from jax.tree_util import Partial\n",
    "from jax.lax import scan\n",
    "import numpyro.distributions as dist\n",
    "import flax.linen as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import math\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "import orbax.checkpoint\n",
    "\n",
    "#Defining master key for jax\n",
    "KEY = random.key(0)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['animation.embed_limit'] = 2**128\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b8ab384da602442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T00:00:55.423974408Z",
     "start_time": "2024-02-25T00:00:53.938469011Z"
    },
    "id": "3b8ab384da602442"
   },
   "outputs": [],
   "source": [
    "# Defining Noised version of original gaussian mixture. q_d corresponds to p_t(0).\n",
    "def p_t(std_t):\n",
    "    means = jnp.meshgrid(jnp.arange(-10., 15., 10), jnp.arange(-10., 15., 10))\n",
    "    means = jnp.stack([m.flatten() for m in means], axis=1)\n",
    "    covs = jnp.repeat(jnp.eye(2)[None]*(.1 + std_t**2), axis=0, repeats=means.shape[0])\n",
    "    weights = random.uniform(random.key(42), (len(means),))\n",
    "    return dist.MixtureSameFamily(component_distribution=dist.MultivariateNormal(means,\n",
    "                                                                                 covariance_matrix=covs),\n",
    "                                  mixing_distribution=dist.Categorical(weights))\n",
    "\n",
    "# Helper function to get the score values on a mesh\n",
    "def get_mesh_score(score_fn):\n",
    "    X, Y = jnp.meshgrid(jnp.linspace(-15, 15), jnp.linspace(-15, 15))\n",
    "    xs = jnp.stack([X.flatten(), Y.flatten()], axis=1)\n",
    "    scores = score_fn(xs)\n",
    "    return X, Y, scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782b3e4-fd88-4490-a7f5-29c128618bf7",
   "metadata": {
    "id": "1782b3e4-fd88-4490-a7f5-29c128618bf7"
   },
   "source": [
    "## Unadjusted Langevin Algorithm\n",
    "\n",
    "In this notebook, we will sample from a learned score model using the Unadjusted Langevin Algorithm (ULA). We refer to the following papers for a presentation of the algorithm and it's performance.\n",
    "\n",
    "* [4] Roberts, G. O., & Tweedie, R. L. (1996). Exponential convergence of Langevin distributions and their discrete approximations. Bernoulli, 341-363.\n",
    "* [5] Durmus, A., Majewski, S., & Miasojedow, B. (2019). Analysis of Langevin Monte Carlo via convex optimization. The Journal of Machine Learning Research, 20(1), 2666-2711."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51aacc96cd032253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T00:00:55.644257785Z",
     "start_time": "2024-02-25T00:00:53.951672057Z"
    },
    "id": "51aacc96cd032253"
   },
   "outputs": [],
   "source": [
    "# ULA kernel\n",
    "def ula(x, key, score_fun, learning_rate):\n",
    "    noise = random.normal(key=key, shape=x.shape)\n",
    "    return x + learning_rate * score_fun(x) + ((2*learning_rate)**.5)*noise\n",
    "\n",
    "# Function that is basically a for loop over ULA step but return every sample.\n",
    "# To better understand the syntax of Jax's scan function go to: https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.scan.html\n",
    "def several_steps_ula(init, key, score_fun, learning_rate, n_steps):\n",
    "    \n",
    "    def my_ula(x, key):\n",
    "        pred = ula(x, key, score_fun, learning_rate)\n",
    "        return pred, pred\n",
    "    return scan(f=my_ula,\n",
    "                init=init,\n",
    "                xs=random.split(key, n_steps))[-1]\n",
    "\n",
    "# This is a helper function to allow for multi step ula.\n",
    "def multiple_chain_ula(init, keys, n_steps, score_fun, learning_rate):\n",
    "    return vmap(Partial(several_steps_ula, n_steps=n_steps, learning_rate=learning_rate, score_fun=score_fun))(init, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5d8327-7b88-481d-bff2-79bbeff267b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T00:00:57.203121099Z",
     "start_time": "2024-02-25T00:00:54.235847384Z"
    },
    "id": "0e5d8327-7b88-481d-bff2-79bbeff267b8"
   },
   "outputs": [],
   "source": [
    "# This cell initializes some generic global variables used throughout the notebook \n",
    "LANGEVIN_LR=1e-2\n",
    "N_EPOCHS=3_000\n",
    "BATCH_SIZE=2048\n",
    "KEY, subkey = random.split(KEY, 2)\n",
    "dataset = p_t(0).sample(subkey, (10_000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe157672-7e50-4c4f-8b2d-e7e978b17afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T00:00:59.393615469Z",
     "start_time": "2024-02-25T00:00:55.612280348Z"
    },
    "id": "fe157672-7e50-4c4f-8b2d-e7e978b17afc"
   },
   "outputs": [],
   "source": [
    "# Performs ULA using the real score\n",
    "KEY, subkey_init, subkey_keys = random.split(KEY, 3)\n",
    "samples_ula_0 = multiple_chain_ula(random.normal(subkey_init, shape=(20, 2))*10,\n",
    "                                   random.split(subkey_keys, 20),\n",
    "                                   learning_rate=LANGEVIN_LR,\n",
    "                                   score_fun=jit(grad(lambda x: p_t(0).log_prob(x))),\n",
    "                                   n_steps=1_000)\n",
    "\n",
    "X, Y, scores = get_mesh_score(vmap(grad(p_t(0).log_prob)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe9cf8-6c65-41a8-829a-7c15c6ffa7d4",
   "metadata": {
    "id": "79fe9cf8-6c65-41a8-829a-7c15c6ffa7d4"
   },
   "source": [
    "We consider $p$ to be a $2$-dimensional Gaussian mixture distribution.\n",
    "Below we visualize the result of running ULA with the real score of $q_d$. We initialize the ULA chain with samples from $\\mathcal{N}(0, 100 \\operatorname{I})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e8aed6-54fe-4b76-823a-e032ddf33295",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T00:01:18.951425440Z",
     "start_time": "2024-02-25T00:00:59.139556864Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "id": "66e8aed6-54fe-4b76-823a-e032ddf33295",
    "outputId": "af23db7d-9431-46e6-f459-f0160182db7e"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axes:\n\u001b[0;32m----> 7\u001b[0m   \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m   ax\u001b[38;5;241m.\u001b[39mquiver(X, Y, scores[:, \u001b[38;5;241m0\u001b[39m], scores[:, \u001b[38;5;241m1\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m   ax\u001b[38;5;241m.\u001b[39mset_xlim(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m)\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/matplotlib/axes/_axes.py:4649\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4647\u001b[0m edgecolors \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   4648\u001b[0m \u001b[38;5;66;03m# Process **kwargs to handle aliases, conflicts with explicit kwargs:\u001b[39;00m\n\u001b[0;32m-> 4649\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_unit_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4650\u001b[0m \u001b[38;5;66;03m# np.ma.ravel yields an ndarray, not a masked array,\u001b[39;00m\n\u001b[1;32m   4651\u001b[0m \u001b[38;5;66;03m# unless its argument is a masked array.\u001b[39;00m\n\u001b[1;32m   4652\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(x)\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/matplotlib/axes/_base.py:2555\u001b[0m, in \u001b[0;36m_AxesBase._process_unit_info\u001b[0;34m(self, datasets, kwargs, convert)\u001b[0m\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;66;03m# Update from data if axis is already set but no unit is set yet.\u001b[39;00m\n\u001b[1;32m   2554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis\u001b[38;5;241m.\u001b[39mhave_units():\n\u001b[0;32m-> 2555\u001b[0m         \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis_name, axis \u001b[38;5;129;01min\u001b[39;00m axis_map\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;66;03m# Return if no axis is set.\u001b[39;00m\n\u001b[1;32m   2558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/matplotlib/axis.py:1706\u001b[0m, in \u001b[0;36mAxis.update_units\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_units\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;124;03m    Introspect *data* for units converter and update the\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;124;03m    ``axis.converter`` instance if necessary. Return *True*\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;124;03m    if *data* is registered for unit conversion.\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1706\u001b[0m     converter \u001b[38;5;241m=\u001b[39m \u001b[43mmunits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_converter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/matplotlib/units.py:183\u001b[0m, in \u001b[0;36mRegistry.get_converter\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# If cache lookup fails, look up based on first element...\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     first \u001b[38;5;241m=\u001b[39m \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_first_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mStopIteration\u001b[39;00m):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/matplotlib/cbook.py:1729\u001b[0m, in \u001b[0;36m_safe_first_finite\u001b[0;34m(obj, skip_nonfinite)\u001b[0m\n\u001b[1;32m   1726\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib does not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1727\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport generators as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1729\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msafe_isfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/array.py:358\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_addressable\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mis_single_device_sharding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharding) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated:\n\u001b[0;32m--> 358\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (sl \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_iter(\u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m sl \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharding, PmapSharding):\n\u001b[1;32m    360\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/pjit.py:245\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 245\u001b[0m   outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_params_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m   executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[1;32m    248\u001b[0m   maybe_fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m    249\u001b[0m       executable, out_tree, args_flat, out_flat, attrs_tracked)\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/pjit.py:140\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m   args_flat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39minit_states, \u001b[38;5;241m*\u001b[39margs_flat]\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mDeviceAssignmentMismatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    142\u001b[0m   fails, \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/core.py:2743\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2739\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[1;32m   2740\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   2741\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[1;32m   2742\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2743\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/core.py:935\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 935\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/pjit.py:1393\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1390\u001b[0m has_explicit_sharding \u001b[38;5;241m=\u001b[39m _pjit_explicit_sharding(\n\u001b[1;32m   1391\u001b[0m     in_shardings, out_shardings, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xla_extension_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m226\u001b[39m:\n\u001b[0;32m-> 1393\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_impl_cache_miss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_argnums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_registry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpxla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshard_arg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxla_extension_version\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m229\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpxla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp_shard_arg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m   1397\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_get_cpp_global_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhas_explicit_sharding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1399\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m xc\u001b[38;5;241m.\u001b[39m_xla\u001b[38;5;241m.\u001b[39mpjit(name, f, call_impl_cache_miss, [], [], donated_argnums,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1400\u001b[0m                       tree_util\u001b[38;5;241m.\u001b[39mdispatch_registry,\n\u001b[1;32m   1401\u001b[0m                       _get_cpp_global_cache(has_explicit_sharding))(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/pjit.py:1376\u001b[0m, in \u001b[0;36m_pjit_call_impl.<locals>.call_impl_cache_miss\u001b[0;34m(*args_, **kwargs_)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_impl_cache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_):\n\u001b[0;32m-> 1376\u001b[0m   out_flat, compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_pjit_call_impl_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m      \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m      \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1381\u001b[0m   fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m   1382\u001b[0m       compiled, tree_structure(out_flat), args, out_flat, [])\n\u001b[1;32m   1383\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out_flat, fastpath_data\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/pjit.py:1312\u001b[0m, in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _most_recent_pjit_call_executable\n\u001b[1;32m   1305\u001b[0m in_shardings \u001b[38;5;241m=\u001b[39m _resolve_in_shardings(\n\u001b[1;32m   1306\u001b[0m     args, in_shardings, out_shardings,\n\u001b[1;32m   1307\u001b[0m     resource_env\u001b[38;5;241m.\u001b[39mphysical_mesh \u001b[38;5;28;01mif\u001b[39;00m resource_env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1309\u001b[0m compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_pjit_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlowering_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoweringParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1313\u001b[0m _most_recent_pjit_call_executable\u001b[38;5;241m.\u001b[39mweak_key_dict[jaxpr] \u001b[38;5;241m=\u001b[39m compiled\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:2269\u001b[0m, in \u001b[0;36mMeshComputation.compile\u001b[0;34m(self, compiler_options)\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(\u001b[38;5;28mself\u001b[39m, compiler_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MeshExecutable:\n\u001b[1;32m   2268\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m compiler_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2269\u001b[0m     executable \u001b[38;5;241m=\u001b[39m \u001b[43mUnloadedMeshExecutable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_hlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompiler_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compiler_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2273\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executable \u001b[38;5;241m=\u001b[39m executable\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:2732\u001b[0m, in \u001b[0;36mUnloadedMeshExecutable.from_hlo\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2729\u001b[0m       mesh \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mmesh  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2730\u001b[0m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 2732\u001b[0m xla_executable, compile_options \u001b[38;5;241m=\u001b[39m \u001b[43m_cached_compilation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspmd_lowering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtuple_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_spmd_lowering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_prop_to_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2735\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmap_nreps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_options_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_replicated\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2739\u001b[0m   semantics_in_shardings \u001b[38;5;241m=\u001b[39m SemanticallyEqualShardings(in_shardings)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:2589\u001b[0m, in \u001b[0;36m_cached_compilation\u001b[0;34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, _allow_propagation_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_keys, compiler_options_values)\u001b[0m\n\u001b[1;32m   2584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, compile_options\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mlog_elapsed_time(\n\u001b[1;32m   2587\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{fun_name}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{elapsed_time}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2588\u001b[0m     fun_name\u001b[38;5;241m=\u001b[39mname, event\u001b[38;5;241m=\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mBACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 2589\u001b[0m   xla_executable \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_or_get_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2590\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xla_executable, compile_options\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/compiler.py:260\u001b[0m, in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, devices, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m    256\u001b[0m use_compilation_cache \u001b[38;5;241m=\u001b[39m (config\u001b[38;5;241m.\u001b[39menable_compilation_cache\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    257\u001b[0m                          backend\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;129;01min\u001b[39;00m supported_platforms)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_compilation_cache:\n\u001b[0;32m--> 260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m compilation_cache\u001b[38;5;241m.\u001b[39mset_once_cache_used(\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: monitoring\u001b[38;5;241m.\u001b[39mrecord_event(\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/jax/compilation_cache/tasks_using_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    266\u001b[0m monitoring\u001b[38;5;241m.\u001b[39mrecord_event(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/jax/compilation_cache/compile_requests_use_cache\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/profiler.py:336\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    335\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/Projets/thèse/tutorial_diffusion/.venv/lib/python3.11/site-packages/jax/_src/compiler.py:236\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(built_c, compile_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    232\u001b[0m                          host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Animate ULA with the real score\n",
    "KEY, subkey = random.split(KEY, 2)\n",
    "samples = p_t(0).sample(subkey, (1000,))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "for ax in axes:\n",
    "  ax.scatter(*samples[:1000].T, color='blue')\n",
    "  ax.quiver(X, Y, scores[:, 0], scores[:, 1], color='black')\n",
    "  ax.set_xlim(-15, 15)\n",
    "  ax.set_ylim(-15, 15)\n",
    "traj_artists, points_artists = [], []\n",
    "for i, traj in enumerate(samples_ula_0[:, :1]):\n",
    "    point_artist = axes[1].scatter(*traj[-1], color=plt.get_cmap(\"rainbow\")(i / (samples_ula_0.shape[0]-1)))\n",
    "    traj_artist, = axes[0].plot(*traj.T, color=plt.get_cmap(\"rainbow\")(i / (samples_ula_0.shape[0]-1)))\n",
    "    traj_artists.append(traj_artist)\n",
    "    points_artists.append(point_artist)\n",
    "artists = traj_artists + points_artists\n",
    "\n",
    "def init():\n",
    "\n",
    "  return artists\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    n_artists = len(artists) //2\n",
    "    for i, traj in enumerate(samples_ula_0[:, :frame + 1]):\n",
    "        artists[i].set_data(traj[:, 0], traj[:, 1])\n",
    "        artists[i + n_artists].set_offsets(traj[-1])\n",
    "    return artists\n",
    "\n",
    "matplotlib.animation.FuncAnimation(fig,  update, frames=jnp.arange(0, 25, 1).tolist(),\n",
    "                    init_func=init, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db118afdc8f7bce",
   "metadata": {
    "collapsed": false,
    "id": "6db118afdc8f7bce",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Hyvärinen Approach [1]\n",
    "\n",
    "We start by the Loss presented in [1]. By integration by parts, it is possible to show that the score matching objective is equivalent to:\n",
    "\n",
    "$$ \\theta \\in \\operatorname{argmin}_{\\theta} \\mathbb{E}_{X \\sim q_d}[\\nabla \\cdot s_{\\theta}(X) + \\frac{1}{2} \\|s_{\\theta}(X)\\|^2] \\,. $$\n",
    "\n",
    "We use a simple MLP (multi-layer perceptron) network to model the score $s_\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b59e28f2defc35",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-25T00:02:02.770272472Z"
    },
    "id": "d8b59e28f2defc35"
   },
   "outputs": [],
   "source": [
    "# This function defines a general training function used throught the paper\n",
    "def train(dataset,\n",
    "          learning_rate,\n",
    "          net_params,\n",
    "          loss_fn,\n",
    "          key,\n",
    "          n_epochs,\n",
    "          batch_size = None,\n",
    "         update_tqdm_period=100):\n",
    "    tx = optax.adam(learning_rate=learning_rate)\n",
    "    opt_state = tx.init(net_params)\n",
    "\n",
    "    # define the heavy lifting function of the training loop\n",
    "    def loop_fn_(sb_k, net_params, opt_state):\n",
    "        sb_k_loss, sb_k_batch = random.split(sb_k, 2)\n",
    "        if batch_size:\n",
    "            batch_data = dataset[random.randint(key=sb_k_batch, maxval=dataset.shape[0], minval=0, shape=(batch_size,))]\n",
    "        else:\n",
    "            batch_data = dataset\n",
    "        loss_val, grad = loss_fn(net_params, batch_data, sb_k_loss)\n",
    "        updates, opt_state = tx.update(grad, opt_state)\n",
    "\n",
    "        net_params = optax.apply_updates(net_params, updates)\n",
    "        return loss_val, net_params, opt_state\n",
    "    # Mark it to be just-in-time compiled\n",
    "    loop_fn = jit(loop_fn_)\n",
    "\n",
    "\n",
    "    pbar = tqdm(enumerate(random.split(key, n_epochs)))\n",
    "    losses = []\n",
    "    for i, sb_k in pbar:\n",
    "        # Do stuff\n",
    "        loss_val, net_params, opt_state = loop_fn(sb_k, net_params, opt_state)\n",
    "\n",
    "        # Plot stuff\n",
    "        if i % update_tqdm_period == 0:\n",
    "            pbar.set_description(f\"Loss: {loss_val:.2E}\")\n",
    "        losses.append(loss_val)\n",
    "    return net_params, losses\n",
    "\n",
    "\n",
    "# Loss from Hyvarinen paper.\n",
    "def make_hyvarinen_loss(net, n_eps_hutch=100, data_dim=2, use_hutching_trick=False):\n",
    "    if use_hutching_trick:\n",
    "        # To be completed\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        def loss_fn(params, data, key):\n",
    "            def score_twice(data):\n",
    "                score = net.apply(params, data)\n",
    "                return score, score\n",
    "            jac, score = vmap(jacfwd(score_twice, has_aux=True))(data)\n",
    "\n",
    "            div = jnp.diagonal(jac, axis1=-2, axis2=-1).sum(axis=-1)\n",
    "            score_norm = (score**2).sum(axis=-1)\n",
    "\n",
    "            return (div + .5 * score_norm).mean()\n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a7964f7562360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T00:02:03.349987828Z",
     "start_time": "2024-02-25T00:02:02.771956468Z"
    },
    "id": "9a1a7964f7562360"
   },
   "outputs": [],
   "source": [
    "# Simple Neural Net from Flax\n",
    "class MLP(nn.Module):              \n",
    "  out_dims: int\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "      x = nn.Dense(128)(x)\n",
    "      x = nn.LayerNorm()(x)\n",
    "      x = nn.leaky_relu(x)\n",
    "      x = nn.Dense(512)(x)\n",
    "      x = nn.LayerNorm()(x)\n",
    "      x = nn.leaky_relu(x)\n",
    "      x = nn.Dense(256)(x)\n",
    "      x = nn.LayerNorm()(x)  \n",
    "      x = nn.leaky_relu(x)\n",
    "      x = nn.Dense(self.out_dims)(x)\n",
    "      return nn.leaky_relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd5231a4992abce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T00:02:03.489835125Z",
     "start_time": "2024-02-25T00:02:02.778917556Z"
    },
    "id": "bbd5231a4992abce"
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "model = MLP(out_dims=2)\n",
    "x = jnp.empty((1, 2))\n",
    "net_params = model.init(random.key(42), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80982b538ebeceaf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-25T00:02:02.783477572Z"
    },
    "id": "80982b538ebeceaf",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "KEY, subkey = random.split(KEY, 2)\n",
    "net_params, losses = train(\n",
    "    dataset=dataset,\n",
    "    learning_rate=1e-4,\n",
    "    net_params=net_params,\n",
    "    loss_fn=value_and_grad(make_hyvarinen_loss(model)),\n",
    "    key=subkey,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d1b27-00b4-4e15-80cf-a6f2c17675a2",
   "metadata": {
    "id": "072d1b27-00b4-4e15-80cf-a6f2c17675a2",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# PLotting the loss\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(jnp.stack(losses))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782cc3d7-2b9a-4a7e-a8fd-a9a6afaefa19",
   "metadata": {
    "id": "782cc3d7-2b9a-4a7e-a8fd-a9a6afaefa19"
   },
   "source": [
    "### Sampling with Hyvarinen Model:\n",
    "\n",
    "We now focus on sampling with the Hyvarinen model musing ULA with the same parameterization as for the case of perfect score, and the same starting distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf2889-2960-47e5-bdc4-e5ddeb78e308",
   "metadata": {
    "id": "bcaf2889-2960-47e5-bdc4-e5ddeb78e308",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Sampling with ULA\n",
    "KEY, subkey_init, subkey_keys = random.split(KEY, 3)\n",
    "samples_ula_0 = multiple_chain_ula(random.normal(subkey_init, shape=(20, 2))*10,\n",
    "                                   random.split(subkey_keys, 20),\n",
    "                                   learning_rate=LANGEVIN_LR,\n",
    "                                   score_fun=jit(lambda x: model.apply(net_params, x)),\n",
    "                                   n_steps=1_000)\n",
    "X, Y, scores = get_mesh_score(lambda xs: vmap(model.apply, in_axes=(None, 0))(net_params, xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf5a59-96d6-4359-b019-bfc6047705e3",
   "metadata": {
    "id": "d7cf5a59-96d6-4359-b019-bfc6047705e3",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Animating with ULA\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "traj_artists, points_artists = [], []\n",
    "for i, traj in enumerate(samples_ula_0[:, :1]):\n",
    "    point_artist = axes[1].scatter(*traj[-1], color=plt.get_cmap(\"rainbow\")(i / (samples_ula_0.shape[0]-1)))\n",
    "    traj_artist, = axes[0].plot(*traj.T, color=plt.get_cmap(\"rainbow\")(i / (samples_ula_0.shape[0]-1)))\n",
    "    traj_artists.append(traj_artist)\n",
    "    points_artists.append(point_artist)\n",
    "artists = traj_artists + points_artists\n",
    "\n",
    "def init():\n",
    "  for ax in axes:\n",
    "      ax.scatter(*dataset[:1000].T, color='blue')\n",
    "      ax.quiver(X, Y, scores[:, 0], scores[:, 1], color='black')\n",
    "      ax.set_xlim(-15, 15)\n",
    "      ax.set_ylim(-15, 15)\n",
    "  return artists\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    n_artists = len(artists) //2\n",
    "    for i, traj in enumerate(samples_ula_0[:, :frame + 1]):\n",
    "        artists[i].set_data(traj[:, 0], traj[:, 1])\n",
    "        artists[i + n_artists].set_offsets(traj[-1])\n",
    "    return artists\n",
    "\n",
    "matplotlib.animation.FuncAnimation(fig,  update, frames=jnp.arange(0, 1_000, 50).tolist(),\n",
    "                    init_func=init, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fd0672d74e689a",
   "metadata": {
    "collapsed": false,
    "id": "67fd0672d74e689a",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Denoising Loss [2]:\n",
    "\n",
    "In [2], the authors propose learning the score of a noised version of $q_d$, that we denote by $q_t$. Formally,\n",
    "$$q_t(x) = \\mathbb{E}_{X \\sim q_d}[q_{t|0}(x | X)] \\, ,$$\n",
    "where $q_{t|0}(x | x_0) = \\mathcal{N}(x; x_{0}, \\upsilon_t^2 \\operatorname{I})$ with $\\upsilon_t > 0$.\n",
    "\n",
    "In this case, estimating the score of $q_t$ via the score mathing objective is equivalent to\n",
    "$$ \\operatorname{argmin}_{\\theta}\\mathbb{E}_{X \\sim q_d, \\epsilon \\sim \\mathcal{N}(0, \\operatorname{I})} [\\|s_{\\theta}(X + \\upsilon_t \\epsilon) - \\nabla \\log q_{t|0}(X + \\upsilon_t \\epsilon|X)\\|^2]  = \\operatorname{argmin}_{\\theta}\\mathbb{E}_{X \\sim q_d, \\epsilon \\sim \\mathcal{N}(0, \\operatorname{I})}[\\|s_{\\theta}(X + \\upsilon_t \\epsilon) + \\upsilon_t^{-1}\\epsilon \\|^2]\\, . $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10fc86db-b957-4650-a8d9-5b7430d11cf2",
   "metadata": {
    "id": "10fc86db-b957-4650-a8d9-5b7430d11cf2",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Function that makes the denoising loss function\n",
    "def make_denoising_loss(net, std=1e-2, data_dim=2):\n",
    "    def loss_fn(params, data, key):\n",
    "        eps = random.normal(key, (data.shape[0], data_dim))\n",
    "        score = net.apply(params, data + std*eps)\n",
    "\n",
    "        loss = ((score + eps/std)**2).sum(axis=-1)\n",
    "\n",
    "        return loss.mean()\n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425b307-93f9-41c5-a8d1-0c3e052a7ccf",
   "metadata": {
    "id": "4425b307-93f9-41c5-a8d1-0c3e052a7ccf",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model = MLP(out_dims=2)\n",
    "x = jnp.empty((1, 2))\n",
    "net_params = model.init(random.key(42), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e313215-c9ca-4f3f-a6ef-83587ecea0c7",
   "metadata": {
    "id": "1e313215-c9ca-4f3f-a6ef-83587ecea0c7",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "KEY, subkey = random.split(KEY, 2)\n",
    "net_params, losses = train(\n",
    "    dataset=dataset,\n",
    "    learning_rate=1e-2,\n",
    "    net_params=net_params,\n",
    "    loss_fn=value_and_grad(make_denoising_loss(model, std=1)),\n",
    "    key=subkey,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    update_tqdm_period=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642c638-bdaa-4e9a-a623-3b734c510ec1",
   "metadata": {
    "id": "8642c638-bdaa-4e9a-a623-3b734c510ec1",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(jnp.stack(losses))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce86912-d588-4168-8374-910414109279",
   "metadata": {
    "id": "7ce86912-d588-4168-8374-910414109279"
   },
   "source": [
    "### Sampling from the learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712c734-1a54-4c58-a3e7-f8b086234d49",
   "metadata": {
    "id": "9712c734-1a54-4c58-a3e7-f8b086234d49",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "KEY, subkey_init, subkey_keys = random.split(KEY, 3)\n",
    "samples_ula_0 = multiple_chain_ula(random.normal(subkey_init, shape=(20, 2))*10,\n",
    "                                   random.split(subkey_keys, 20),\n",
    "                                   learning_rate=LANGEVIN_LR,\n",
    "                                   score_fun=jit(lambda x: model.apply(net_params, x)),\n",
    "                                   n_steps=1_000)\n",
    "\n",
    "X, Y, scores = get_mesh_score(lambda xs: vmap(model.apply, in_axes=(None, 0))(net_params, xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec7667-9c55-4122-868f-99f97cf0a27d",
   "metadata": {
    "id": "adec7667-9c55-4122-868f-99f97cf0a27d",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.scatter(*dataset[:1000].T, color='blue', alpha=.6)\n",
    "    ax.quiver(X, Y, scores[:, 0], scores[:, 1], color='black')\n",
    "    ax.set_xlim(-15, 15)\n",
    "    ax.set_ylim(-15, 15)\n",
    "\n",
    "traj_artists, points_artists = [], []\n",
    "for i, traj in enumerate(samples_ula_0[:, :1]):\n",
    "    point_artist = axes[1].scatter(*traj[-1], color=plt.get_cmap(\"rainbow\")(i / (samples_ula_0.shape[0]-1)), alpha=.8)\n",
    "    traj_artist, = axes[0].plot(*traj.T, color=plt.get_cmap(\"rainbow\")(i / (samples_ula_0.shape[0]-1)), alpha=.8)\n",
    "    traj_artists.append(traj_artist)\n",
    "    points_artists.append(point_artist)\n",
    "artists = traj_artists + points_artists\n",
    "\n",
    "def init():\n",
    "\n",
    "  return artists\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    n_artists = len(artists) //2\n",
    "    for i, traj in enumerate(samples_ula_0[:, :frame + 1]):\n",
    "        artists[i].set_data(traj[:, 0], traj[:, 1])\n",
    "        artists[i + n_artists].set_offsets(traj[-1])\n",
    "    return artists\n",
    "\n",
    "matplotlib.animation.FuncAnimation(fig,  update, frames=jnp.arange(0, 1_000, 10).tolist(),\n",
    "                    init_func=init, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7a3c8-7f72-4ea0-aacd-af22b9ed3af9",
   "metadata": {
    "id": "dfb7a3c8-7f72-4ea0-aacd-af22b9ed3af9"
   },
   "source": [
    "## Noise Conditional Score Networks (NCSN) [3]\n",
    "\n",
    "We now consider the approach presented in [3], which consist of using a single network $s_\\theta(x, \\upsilon_t)$ that approaches jointly the score of a sequence of distributions $\\{q_t\\}_{t \\in [\\varepsilon, 1]}$ defined as above but for a sequence of $\\{\\upsilon_t\\}_{t \\in [\\varepsilon, 1]}$. Here, we define $\\upsilon_\\varepsilon=0.02$, $\\upsilon_1 = 10$ and $\\upsilon_t = (\\upsilon_\\varepsilon^{1/\\rho} + \\frac{t - \\varepsilon}{1-\\varepsilon} (\\upsilon_1^{1/\\rho} - \\upsilon_\\varepsilon^{1/\\rho}))^\\rho$ with $\\rho=5$.\n",
    "\n",
    "To do so, we consider the following loss\n",
    "$$ \\operatorname{argmin}_{\\theta}\\mathbb{E}_{t \\in \\mathcal{U}(\\varepsilon, 1)}\\left[\\gamma_t^2\\mathbb{E}_{X \\sim q_d, \\epsilon \\sim \\mathcal{N}(0, \\operatorname{I})}[\\|s_{\\theta}(X + \\upsilon_t \\epsilon) - \\upsilon_t^{-1}\\epsilon \\|^2]\\right]\\, ,$$\n",
    "where $\\gamma_t = \\upsilon_t$ is a weighting coefficient.\n",
    "The goal of this sequence of distributions is to allow for efficient sequential ULA steps, since the distance between two consecutive distributions $q_{t_1}$ and $q_{t_2}$ is close for $t_1 \\approx t_2$, thus using samples from $q_{t_2}$ to initialize ULA for $q_{t_1}$ would be a good initialization. Furthemore, this allows to approximate better $p$ by choosing $\\varepsilon$ small.\n",
    "\n",
    "We start by visualizing the sequence of distributions $\\{q_t\\}_{t \\in [\\varepsilon, 1]}$ defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91249a99935f285",
   "metadata": {
    "id": "a91249a99935f285",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "KEY, subkey = random.split(KEY, 2)\n",
    "std_min = 0.02\n",
    "std_max = 10\n",
    "p=5\n",
    "stds = (std_max ** (1/p) + jnp.linspace(1, 0, 100)*(std_min**(1/p) - std_max**(1/p)))**p #taken from Karras2022 (https://arxiv.org/pdf/2206.00364.pdf)\n",
    "samples = vmap(lambda std_t, key: p_t(std_t).sample(key, sample_shape=(1_000,)))(stds, random.split(subkey, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b61b450ed1c11",
   "metadata": {
    "id": "bb7b61b450ed1c11",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "def animate(t):\n",
    "    plt.cla()\n",
    "    plt.scatter(*samples[t].T)\n",
    "    plt.xlim(-15, 15)\n",
    "    plt.ylim(-15, 15)\n",
    "\n",
    "matplotlib.animation.FuncAnimation(fig, animate, frames=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925e6d1-e8cb-44d8-91de-63df6521b7bf",
   "metadata": {
    "id": "2925e6d1-e8cb-44d8-91de-63df6521b7bf",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def make_ncns_loss(net, std_min=1e-2, std_max=10, data_dim=2, n_time_samples=25):\n",
    "    def loss_fn(params, data, key):\n",
    "        key_uniform, key_noise = random.split(key, 2)\n",
    "        #stds = random.uniform(key_uniform, minval=std_min, maxval=std_max, shape=(data.shape[0], n_time_samples, 1))\n",
    "        stds = jnp.exp(random.normal(key_uniform, shape=(data.shape[0], n_time_samples, 1))*1.2 - .5).clip(std_min, std_max)\n",
    "        eps = random.normal(key, (data.shape[0], n_time_samples, 2))\n",
    "        x_t = data[:, None] + stds * eps\n",
    "        score = net.apply(params, x_t, stds)\n",
    "\n",
    "        loss = ((score + eps/stds[None])**2).sum(axis=-1)\n",
    "        loss_weights = stds[..., 0]**2\n",
    "        return  (loss_weights*loss).mean()\n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fcddd-a41a-4c72-94ff-4687b27a7188",
   "metadata": {
    "id": "c96fcddd-a41a-4c72-94ff-4687b27a7188",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):                    \n",
    "  out_dims: int\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x, std):\n",
    "    std_emb = .25 * jnp.log(std)\n",
    "    x = nn.Dense(256)(jnp.concatenate((x, std_emb), axis=-1))\n",
    "    x = nn.LayerNorm()(x)              \n",
    "    x = nn.leaky_relu(x)\n",
    "    x = nn.Dense(512)(x)\n",
    "    x = nn.leaky_relu(x)\n",
    "    x = nn.Dense(256)(x)   \n",
    "    x = nn.LayerNorm()(x)               \n",
    "    x = nn.leaky_relu(x)\n",
    "    x = nn.Dense(self.out_dims)(x)       \n",
    "    return nn.leaky_relu(x)\n",
    "\n",
    "model = MLP(out_dims=2)\n",
    "x, std = jnp.empty((1, 2)), jnp.empty((1, 1))\n",
    "net_params = model.init(random.key(42), x, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626786d-3ae0-4960-96c8-e9c7e0a29993",
   "metadata": {
    "id": "0626786d-3ae0-4960-96c8-e9c7e0a29993",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "KEY, subkey = random.split(KEY, 2)\n",
    "net_params, losses = train(\n",
    "    dataset=dataset,\n",
    "    learning_rate=1e-2,\n",
    "    net_params=net_params,\n",
    "    loss_fn=value_and_grad(make_ncns_loss(model, std_min=std_min, std_max=std_max, n_time_samples=2)),\n",
    "    key=subkey,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    update_tqdm_period=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656dc46-6f8c-40d0-81a9-cc444b2ba096",
   "metadata": {
    "id": "c656dc46-6f8c-40d0-81a9-cc444b2ba096",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(jnp.stack(losses))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef92696-dfbb-4cad-b0e0-ef70b87cbdca",
   "metadata": {
    "id": "bef92696-dfbb-4cad-b0e0-ef70b87cbdca"
   },
   "source": [
    "## Sampling with NCSN\n",
    "\n",
    "We now consider doing sequentially ULA for each $q_t$, starting from $q_{100}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda48a4-a15a-470c-9c6a-12787d5f6ce9",
   "metadata": {
    "id": "7dda48a4-a15a-470c-9c6a-12787d5f6ce9",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def sequential_ula(\n",
    "        initial_samples,\n",
    "        key,\n",
    "        stds_sequence,\n",
    "        n_iter_per_timestep,\n",
    "        score_fun,\n",
    "        learning_rate_ratio,\n",
    "        n_chains,\n",
    "):\n",
    "    def scan_fn(x, meta):\n",
    "        key, lr, std = meta\n",
    "        samples = multiple_chain_ula(x,\n",
    "                                     random.split(key, n_chains),\n",
    "                                     learning_rate=lr,\n",
    "                                     score_fun=Partial(score_fun, std=std[None]),\n",
    "                                     n_steps=n_iter_per_timestep)\n",
    "        return samples[:, -1], samples\n",
    "    return scan(f=scan_fn,\n",
    "                init=initial_samples,\n",
    "                xs=(random.split(key, len(stds_sequence)),\n",
    "                    learning_rate_ratio * (stds_sequence / stds_sequence[-1])**2,\n",
    "                    stds_sequence))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352135b4-91f5-4d70-8156-80a7891967f2",
   "metadata": {
    "id": "352135b4-91f5-4d70-8156-80a7891967f2",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "KEY, subkey_init = random.split(KEY, 2)\n",
    "samples_ncnn = sequential_ula(\n",
    "    random.normal(subkey_init, shape=(20, 2))*std_max,\n",
    "    subkey_init,\n",
    "    stds_sequence=stds[::-1],\n",
    "    n_iter_per_timestep=5,\n",
    "    score_fun=jit(lambda x, std: model.apply(net_params, x, std)),\n",
    "    learning_rate_ratio=1e-4,\n",
    "    n_chains=20\n",
    ")\n",
    "score_quivers = []\n",
    "for std in stds[::-1]:\n",
    "    X, Y, scores = get_mesh_score(lambda xs: vmap(model.apply, in_axes=(None, 0, None))(net_params, xs, std[None]))\n",
    "    score_quivers.append(scores / jnp.abs(scores).max(axis=0)[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f23691-623a-4714-8766-417ed85cef24",
   "metadata": {
    "id": "c7f23691-623a-4714-8766-417ed85cef24",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.scatter(*dataset[:1000].T, color='blue', alpha=.6)\n",
    "    ax.quiver(X, Y, scores[:, 0], scores[:, 1], color='black')\n",
    "    ax.set_xlim(-15, 15)\n",
    "    ax.set_ylim(-15, 15)\n",
    "\n",
    "traj_artists, points_artists, quiver_artists = [], [], []\n",
    "for ax in axes:\n",
    "    quiver_artists.append(ax.quiver(X, Y, score_quivers[0][:, 0], score_quivers[0][:, 1], color='black'))\n",
    "for i, traj in enumerate(jnp.swapaxes(samples_ncnn[:1], 0, 1)):\n",
    "    point_artist = axes[1].scatter(*traj[-1, -1], color=plt.get_cmap(\"rainbow\")(i / (samples_ncnn.shape[1]-1)), alpha=.8)\n",
    "    traj_artist, = axes[0].plot(*traj.reshape(-1, 2).T, color=plt.get_cmap(\"rainbow\")(i / (samples_ncnn.shape[1]-1)), alpha=.5)\n",
    "    traj_artists.append(traj_artist)\n",
    "    points_artists.append(point_artist)\n",
    "artists = traj_artists + points_artists + quiver_artists\n",
    "\n",
    "def init():\n",
    "\n",
    "  return artists\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    n_artists = (len(artists) - 2) //2\n",
    "    for i, traj in enumerate(jnp.swapaxes(samples_ncnn[max(frame-40, 0):frame + 1], 0, 1)):\n",
    "        artists[i].set_data(traj[..., 0].reshape(-1), traj[..., 1].reshape(-1))\n",
    "        artists[i + n_artists].set_offsets(traj[-1, -1])\n",
    "    artists[-2].set_UVC(score_quivers[frame][:, 0], score_quivers[frame][:, 1])\n",
    "    artists[-1].set_UVC(score_quivers[frame][:, 0], score_quivers[frame][:, 1])\n",
    "    return artists\n",
    "\n",
    "matplotlib.animation.FuncAnimation(fig,  update, frames=jnp.arange(0, 100, 2).tolist(),\n",
    "                    init_func=init, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43fee3-a79f-4304-819e-babb383f08e3",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## DDIM Sampling\n",
    "\n",
    "Note that the sequence of distributions defined above match the marginals of the following Markov chain:\n",
    "\n",
    "$$ X_t = X_{t-1} + (\\upsilon_t^2 - \\upsilon_{t-1}^2)^{1/2} \\epsilon_t \\,,$$\n",
    "\n",
    "where $\\epsilon_t \\sim \\mathcal{N}(0, \\operatorname{I})$ for $X_0 \\sim q_{d}$. We denote the Law of $X_t$ knowing $X_{t-1}$ as $q_{t|t-1}(x_t|x_{t-1}) = \\mathcal{N}(x_t; x_{t-1}, (\\upsilon_t^2 - \\upsilon_{t-1}^2) \\operatorname{I})$.\n",
    "\n",
    "### Inference distribution\n",
    "\n",
    "We now focus on the DDIM sampler [4]. The goal of DDIM is to propose a backward Markov chain that matches well the Markov chain defined above. To do so, it focus first on the Law of $X_{1:T}$ knowing $X_{0}$.\n",
    "It relies on the inference distribution\n",
    "\n",
    "$$ q_{1:T}^{\\eta}(x_{1:T} | x_0) = q_{T|0} \\prod_{i=2}^{T} q_{t-1 | t, 0}^{\\eta_{t-1}}(x_{t-1}|x_t, x_0)\\,,$$ \n",
    "\n",
    "where $\\eta \\in [0, \\infty) \\times (0, \\upsilon_1) \\times \\cdots \\times (0, \\upsilon_{T-1})$ and \n",
    "\n",
    "$$  q_{t-1 | t, 0}^{\\eta_{t-1}}(x_{t-1}|x_t, x_0) = \\mathcal{N}(x_0 + [(\\upsilon_{t-1}^2 - \\eta_{t-1}^2)^{1/2} / \\upsilon_{t}] (x_t - x_0), \\eta_{t-1}^2 \\operatorname{I}) \\,. $$\n",
    "\n",
    "The key property of the inference distribution is that it matches the laws of $X_t$ knowing $X_0$:\n",
    "\n",
    "$$ q_{t|0} = \\int q_{1:T}^{\\eta}(x_{1:T} | x_0) dx_{1:t-1} dx_{t+1:T} = \\mathcal{N}(x_0, \\upsilon_{t}^2 \\operatorname{I}) \\,.$$\n",
    "\n",
    "Indeed, for the *particular choice* of $\\eta_t = (\\upsilon_t^2 - \\upsilon_{t-1}^2)^{1/2} (\\upsilon_{t-1} / \\upsilon_t)$ we retrieve the Bayes decomposition:\n",
    "\n",
    "$$ q_{t-1 | t, 0}^{\\eta_t} = \\frac{q_{t|t-1}(x_t | x_{t-1}) q_{t-1|0}(x_{t-1}|x_{0})}{q_{t|0}(x_t|x_0)}$$\n",
    "\n",
    "[4] Song, J., Meng, C., & Ermon, S. (2020, October). Denoising Diffusion Implicit Models. In International Conference on Learning Representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c5b3cd-0416-4999-9cd4-1186dafeb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_process(x_0, x_t, sigma_t, sigma_t_1, eta_t_1):\n",
    "    eps = x_t - x_0\n",
    "    coeff_eps = ((sigma_t_1**2 - eta_t_1**2) / (sigma_t**2))**.5\n",
    "    return x_0 + coeff_eps * eps\n",
    "\n",
    "\n",
    "def inference_process_sampling(x_T, key, x_0, etas, sigmas):\n",
    "    def _infproc_step(x_t, meta):\n",
    "        key, eta_t_1, sig_t, sig_t_1 = meta\n",
    "        x_t_1 = inference_process(x_0, x_t, sig_t, sig_t_1, eta_t_1)\n",
    "        x_t_1 = x_t_1 + eta_t_1 * random.normal(key, shape=x_t_1.shape)\n",
    "        return x_t_1, x_t_1\n",
    "    n_steps = len(etas)\n",
    "    return scan(f=_infproc_step,\n",
    "                init=x_T,\n",
    "                xs=(random.split(key, n_steps), etas[::-1], sigmas[1:][::-1], sigmas[:-1][::-1]))[-1]\n",
    "\n",
    "\n",
    "def make_inference_process_sampler(N, eps, p=5, std_min=0.02, std_max=10.):\n",
    "    stds = (std_max ** (1/p) + jnp.linspace(1, 0, N)*(std_min**(1/p) - std_max**(1/p)))**p\n",
    "    etas = ((stds[1:] ** 2 - stds[:-1] **2)**.5) * (stds[:-1] / stds[1:]) * eps\n",
    "    return jit(vmap(Partial(inference_process_sampling,\n",
    "                            etas=etas,\n",
    "                            sigmas=stds), in_axes=(0, 0, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda4212-68fd-4d54-8fc8-240377f5fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_inf_proc_sampler = make_inference_process_sampler(100, 1)\n",
    "other_inf_proc_sampler = make_inference_process_sampler(100, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a1f64-07e0-45db-83d2-4d660d746cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY, subkey_init, subkey_bayes, subkey_2 = random.split(KEY, 4)\n",
    "initial_samples = random.normal(subkey_init, shape=(20, 1))*std_max\n",
    "\n",
    "bayes_samples = bayes_inf_proc_sampler(initial_samples, random.split(subkey_bayes, 20), jnp.zeros((1,)))\n",
    "other_samples = other_inf_proc_sampler(initial_samples, random.split(subkey_2, 20), jnp.zeros((1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6806727-e000-457f-9dbd-6f0795ed3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = other_samples.shape[1]\n",
    "range_to_plot = jnp.linspace(1, 0, n_steps)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(-10, 10)\n",
    "ax.set_yscale('symlog')\n",
    "ax.fill_between(range_to_plot[::-1], -stds[:-1]*3, stds[:-1]*3, color='red', alpha=.3)\n",
    "\n",
    "artists = [\n",
    "    ax.plot([], [],  linestyle='dashed', color='blue', marker='o', markersize=3)[0], \n",
    "    ax.plot([], [],  linestyle='dashed', color='green', marker='o', markersize=3)[0]\n",
    "]\n",
    "\n",
    "def init():\n",
    "\n",
    "  return artists\n",
    "\n",
    "def update(t):\n",
    "\n",
    "    artists[0].set_data(range_to_plot[:t+1], bayes_samples[0, :t+1])\n",
    "    artists[1].set_data(range_to_plot[:t+1], other_samples[0, :t+1])\n",
    "    return artists\n",
    "\n",
    "matplotlib.animation.FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=jnp.arange(0, 100, 1).tolist(),\n",
    "    init_func=init, blit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa35ec96-5545-4112-9a36-e4c0e1d8cf3f",
   "metadata": {},
   "source": [
    "### DDIM sampling\n",
    "\n",
    "Then, to generate the backward chain from DDIM, one simply replace in every $q_{t-1|t, 0}$ the $X_0$ term by Tweedie's approximation of the mean obtained with the score net:\n",
    "\n",
    "$$ \\mu_{t, \\theta}(x_t) = x_t + \\upsilon_t^2 s_{\\theta}(x_t, \\upsilon_t)\\,. $$\n",
    "\n",
    "By replacing $q_{T|0}$ by $\\lambda = \\mathcal{N}(0, \\upsilon_T^2 \\operatorname{I})$ we obtain\n",
    "\n",
    "$$p_{0:T}(x_{0:T}) = \\lambda(x_T) \\prod_{t=1}^{T} p_{t-1|t}(x_{t-1}| x_t) \\,,$$\n",
    "\n",
    "where $p_{t-1|t} = q_{t-1|t, 0}(x_{t-1}|x_{t}, \\mu_{t, \\theta}(x_t))$ for $t > 1$ and $p_{0|1} = \\mathcal{N}(\\mu_{1, \\theta}(x_1), \\eta_0^2 \\operatorname{I})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1014a8-8cb2-474c-9e99-4b91f7eff3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddim_sampling(x_T, key, etas, sigmas, score_net):\n",
    "    \n",
    "    def _ddim_step(x_t, meta):\n",
    "        key, eta_t_1, sig_t, sig_t_1 = meta\n",
    "        pred_x_0 = x_t + (sig_t**2) * score_net(x_t, sig_t)\n",
    "        x_t_1 = inference_process(pred_x_0, x_t, sig_t, sig_t_1, eta_t_1)\n",
    "        x_t_1 = x_t_1 + eta_t_1 * random.normal(key, shape=x_t_1.shape)\n",
    "        return x_t_1, x_t_1\n",
    "        \n",
    "    n_steps = len(etas) - 1\n",
    "    x_1, x_traj = scan(f=_ddim_step,\n",
    "                init=x_T,\n",
    "                xs=(random.split(key, n_steps), etas[1:][::-1], sigmas[1:][::-1], sigmas[:-1][::-1]))\n",
    "    x_0 = x_1 + (sigmas[0]**2) * score_net(x_1, sigmas[0])\n",
    "    x_0 = x_0 + etas[0] * random.normal(key, shape=x_0.shape) \n",
    "    return jnp.concatenate((x_traj, x_0[None]), axis=0)\n",
    "\n",
    "\n",
    "def make_ddim_sampler(N, eps, score_net, eta_0=0., p=5, std_min=0.02, std_max=10.):\n",
    "    stds = (std_max ** (1/p) + jnp.linspace(1, 0, N)*(std_min**(1/p) - std_max**(1/p)))**p\n",
    "    etas = jnp.clip(((stds[1:] ** 2 - stds[:-1] **2)**.5) * (stds[:-1] / stds[1:]) * eps, 0, stds[:-1] - 1e-8)\n",
    "    etas = jnp.concatenate((jnp.array([eta_0]), etas), axis=0)\n",
    "    return jit(vmap(Partial(ddim_sampling,\n",
    "                            etas=etas,\n",
    "                            sigmas=stds,\n",
    "                           score_net=score_net), in_axes=(0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc52213-3ed8-43b7-8d12-3e71f1703a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_ddim_sampler = make_ddim_sampler(50, 1, score_net=lambda x, std: model.apply(net_params, x, std[None]))\n",
    "other_ddim_sampler = make_ddim_sampler(50, 0.2, score_net=lambda x, std: model.apply(net_params, x, std[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e52ca4-b18f-4ce0-b3f6-5560db4c6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY, subkey_init, subkey_bayes, subkey_other = random.split(KEY, 4)\n",
    "initial_samples = random.normal(subkey_init, shape=(100, 2))*std_max\n",
    "\n",
    "bayes_samples = bayes_ddim_sampler(initial_samples, random.split(subkey_bayes, 100))\n",
    "other_samples = other_ddim_sampler(initial_samples, random.split(subkey_other, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e208f454-797f-4e9d-967b-83e58414f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.scatter(*dataset[:1000].T, color='blue', alpha=.6)\n",
    "    # ax.quiver(X, Y, scores[:, 0], scores[:, 1], color='black')\n",
    "    ax.set_xlim(-15, 15)\n",
    "    ax.set_ylim(-15, 15)\n",
    "axes[0].set_title('DDIM other')\n",
    "axes[1].set_title('DDIM Bayes')\n",
    "other_artists, bayes_artists, quiver_artists = [], [], []\n",
    "# for ax in axes:\n",
    "#     quiver_artists.append(ax.quiver(X, Y, score_quivers[0][:, 0], score_quivers[0][:, 1], color='black'))\n",
    "\n",
    "other_artists.append(axes[0].scatter(*initial_samples.T, color='orange'))\n",
    "bayes_artists.append(axes[1].scatter(*initial_samples.T, color='red'))\n",
    "artists = other_artists + bayes_artists + quiver_artists\n",
    "\n",
    "def init():\n",
    "\n",
    "  return artists\n",
    "\n",
    "\n",
    "def update(t):\n",
    "    f1, f2 = t\n",
    "    artists[0].set_offsets(other_samples[:, f1])\n",
    "    artists[1].set_offsets(bayes_samples[:, f2])\n",
    "    # artists[-2].set_UVC(score_quivers[frame][:, 0], score_quivers[frame][:, 1])\n",
    "    # artists[-1].set_UVC(score_quivers[frame][:, 0], score_quivers[frame][:, 1])\n",
    "    return artists\n",
    "\n",
    "min_len = min(bayes_samples.shape[1], other_samples.shape[1])\n",
    "t2 = jnp.trunc(jnp.linspace(0, bayes_samples.shape[1], min_len)).astype(int)\n",
    "t1 = jnp.trunc(jnp.linspace(0, other_samples.shape[1], min_len)).astype(int)\n",
    "matplotlib.animation.FuncAnimation(fig,  update, frames=zip(t1, t2),\n",
    "                    init_func=init, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03bc7f6-5343-4df9-9fe7-0363adb9b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ot import max_sliced_wasserstein_distance\n",
    "KEY, subkey_init = random.split(KEY, 2)\n",
    "initial_samples = random.normal(subkey_init, shape=(2000, 2))*std_max\n",
    "ddim_sws = {}\n",
    "for eps in [0., 0.1, 0.5, 1.]:\n",
    "    ddim_sws[eps] = {'N': [], 'sw': []}\n",
    "    for N in jnp.arange(2, 11, 1)**2:\n",
    "        KEY, subkey_sampler = random.split(KEY, 2)\n",
    "        samples = make_ddim_sampler(N, eps, score_net=lambda x, std: model.apply(net_params, x, std[None]))(initial_samples, random.split(subkey_sampler, initial_samples.shape[0]))\n",
    "        sw = max_sliced_wasserstein_distance(samples[:,-1], dataset, n_projections=1000)\n",
    "        ddim_sws[eps]['N'].append(N)\n",
    "        ddim_sws[eps]['sw'].append(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8b75d-d8b8-43c8-aeae-264276ecbd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "for c, (eps, eps_data) in zip(plt.get_cmap(\"rainbow\")(jnp.arange(len(ddim_sws)) / (len(ddim_sws) - 1)), ddim_sws.items()):\n",
    "    ax.plot(eps_data['N'], eps_data['sw'], color=c, marker='*', linestyle='dashed', label=eps)\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('Sliced Wasserstein')\n",
    "ax.set_xlabel('N')\n",
    "ax.legend()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4951a6-e4b0-4653-ac47-9592b4d890e2",
   "metadata": {},
   "source": [
    "# Extra: Celeb dataset and Hugging Faces \n",
    "\n",
    "We now consider the dataset to be the Celeba HQ 256 and we use the pretrained model from Hugging Faces' diffusers library (https://github.com/huggingface/diffusers).\n",
    "\n",
    "The main difference with the previous sections, is that, as in [4], they use the *Variance Preserving* framework, which corresponds to simply changing the perturbation kernel to:\n",
    "\n",
    "$$ q_{t|0}(x_t|x_0) = \\mathcal{N}(x_t; \\sqrt{\\alpha_t} x_0, (1 - \\alpha_t) \\operatorname{I})\\,,$$\n",
    "\n",
    "where ${\\alpha_t}_{t \\in [\\varepsilon, 1]}$ is such that $\\alpha_t \\in (0, 1)$ and $\\lim_{t\\rightarrow 1} \\alpha_t = 0$. All the calculations above are feasible with this perturbation Kernel, except that the distribution $\\lambda_n = \\mathcal{N}(0, \\operatorname{I})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f1f89-3dca-4013-9bf0-688639f6a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMPipeline\n",
    "\n",
    "model_id = \"google/ddpm-ema-celebahq-256\"\n",
    "\n",
    "pipe = DDIMPipeline.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd8626-57d0-4437-bb79-186cee8c77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(eta=1, num_inference_steps=10).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f13d8b-0b05-413b-b162-c9050825c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(eta=0, num_inference_steps=10).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a775ec-6a3a-4f09-9c44-d9f445a64a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
